#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„RAGæ¼”ç¤ºï¼šä½¿ç”¨ç« èŠ‚åˆ†å—ç­–ç•¥æ”¹è¿›æ£€ç´¢æ•ˆæœ
"""

import os
import re
import json
from typing import List, Tuple
from tqdm import tqdm
from pymilvus import MilvusClient, model as milvus_model
from openai import OpenAI


def parse_articles_with_chapter_context(file_path: str) -> List[Tuple[str, str]]:
    """
    æŒ‰æ¡æ–‡åˆ†å‰²ï¼Œä½†ä¿ç•™ç« èŠ‚ä¸Šä¸‹æ–‡ä¿¡æ¯
    """

    with open(file_path, "r", encoding="utf-8") as file:
        content = file.read()

    # æŒ‰ç« èŠ‚åˆ†å‰²ï¼ˆ#### å¼€å¤´çš„æ ‡é¢˜ï¼‰
    chapter_pattern = r"^####\s+(.+)$"
    chapter_matches = list(re.finditer(chapter_pattern, content, re.MULTILINE))

    articles = []

    for i, match in enumerate(chapter_matches):
        chapter_title = match.group(1).strip()
        start_pos = match.start()

        # ç¡®å®šç« èŠ‚å†…å®¹çš„ç»“æŸä½ç½®
        if i + 1 < len(chapter_matches):
            end_pos = chapter_matches[i + 1].start()
            chapter_content = content[start_pos:end_pos].strip()
        else:
            chapter_content = content[start_pos:].strip()

        # æŸ¥æ‰¾è¯¥ç« èŠ‚ä¹‹å‰çš„ç¼–ã€éƒ¨åˆ†ä¿¡æ¯
        content_before = content[:start_pos]

        # æŸ¥æ‰¾æœ€è¿‘çš„ç¼–æ ‡é¢˜ï¼ˆ### å¼€å¤´ï¼‰
        part_matches = list(re.finditer(r"^###\s+(.+)$", content_before, re.MULTILINE))
        current_part = part_matches[-1].group(1).strip() if part_matches else ""

        # æŸ¥æ‰¾æœ€è¿‘çš„æ›´é«˜çº§æ ‡é¢˜ï¼ˆ## å¼€å¤´ï¼‰
        book_matches = list(re.finditer(r"^##\s+(.+)$", content_before, re.MULTILINE))
        current_book = book_matches[-1].group(1).strip() if book_matches else ""

        # æ„å»ºå®Œæ•´çš„å±‚çº§æ ‡é¢˜
        full_title_parts = []
        if current_book:
            full_title_parts.append(current_book)
        if current_part:
            full_title_parts.append(current_part)
        full_title_parts.append(f"ç¬¬{chapter_title}")

        chapter_context = " / ".join(full_title_parts)

        # æŒ‰æ¡æ–‡åˆ†å‰²ï¼ˆ**ç¬¬XXXæ¡** æ ¼å¼ï¼‰
        article_pattern = r"\*\*ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡\*\*"
        article_matches = list(re.finditer(article_pattern, chapter_content))

        for j, article_match in enumerate(article_matches):
            article_title_match = article_match.group(0)
            article_start = article_match.start()

            # ç¡®å®šæ¡æ–‡å†…å®¹çš„ç»“æŸä½ç½®
            if j + 1 < len(article_matches):
                article_end = article_matches[j + 1].start()
                article_content = chapter_content[article_start:article_end].strip()
            else:
                article_content = chapter_content[article_start:].strip()

            # æ„å»ºåŒ…å«ç« èŠ‚ä¸Šä¸‹æ–‡çš„æ ‡é¢˜å’Œå†…å®¹
            full_article_title = f"{chapter_context} / {article_title_match}"

            # åœ¨æ¡æ–‡å†…å®¹å‰åŠ ä¸Šä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä½¿embeddingèƒ½ç†è§£æ›´ä¸°å¯Œçš„è¯­ä¹‰
            enhanced_content = f"ã€{full_article_title}ã€‘\n\n{article_content}"

            articles.append((full_article_title, enhanced_content))

    return articles


def build_optimized_rag_system(file_path: str, collection_name: str = "optimized_rag_collection"):
    """
    æ„å»ºä¼˜åŒ–çš„RAGç³»ç»Ÿ
    """

    print("ğŸ“– è§£ææ–‡æ¡£å¹¶ç”Ÿæˆä¼˜åŒ–åˆ†å—...")
    articles = parse_articles_with_chapter_context(file_path)
    print(f"âœ… å…±ç”Ÿæˆ {len(articles)} ä¸ªæ¡æ–‡å—")

    # ä½¿ç”¨é»˜è®¤embeddingæ¨¡å‹ï¼ˆåœ¨å®é™…é¡¹ç›®ä¸­å»ºè®®ä½¿ç”¨æ›´å¼ºçš„ä¸­æ–‡æ¨¡å‹å¦‚BGEï¼‰
    print("ğŸ”§ åˆå§‹åŒ–Embeddingæ¨¡å‹...")
    embedding_model = milvus_model.DefaultEmbeddingFunction()

    # æµ‹è¯•embeddingç»´åº¦
    test_embedding = embedding_model.encode_queries(["æµ‹è¯•"])[0]
    embedding_dim = len(test_embedding)
    print(f"âœ… Embeddingç»´åº¦: {embedding_dim}")

    # åˆå§‹åŒ–Milvuså®¢æˆ·ç«¯
    print("ğŸ—„ï¸  åˆå§‹åŒ–Milvusæ•°æ®åº“...")
    milvus_client = MilvusClient(uri="./optimized_milvus.db")

    # å¦‚æœcollectionå·²å­˜åœ¨åˆ™åˆ é™¤
    if milvus_client.has_collection(collection_name):
        milvus_client.drop_collection(collection_name)
        print("ğŸ—‘ï¸  åˆ é™¤å·²å­˜åœ¨çš„collection")

    # åˆ›å»ºæ–°collection
    milvus_client.create_collection(
        collection_name=collection_name,
        dimension=embedding_dim,
        metric_type="COSINE",  # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå¯¹é•¿åº¦å½’ä¸€åŒ–æ›´å‹å¥½
        consistency_level="Strong"
    )
    print("âœ… åˆ›å»ºæ–°collectionæˆåŠŸ")

    # ç”Ÿæˆembeddingså¹¶æ’å…¥æ•°æ®
    print("ğŸš€ ç”Ÿæˆembeddingså¹¶æ’å…¥æ•°æ®...")

    # åªå¯¹æ–‡æœ¬å†…å®¹ç”Ÿæˆembeddingï¼Œä¸åŒ…æ‹¬æ ‡é¢˜å‰ç¼€
    text_content_only = [content for _, content in articles]
    doc_embeddings = embedding_model.encode_documents(text_content_only)

    data = []
    for i, ((title, content), embedding) in enumerate(tqdm(
        zip(articles, doc_embeddings),
        desc="å‡†å¤‡æ•°æ®",
        total=len(articles)
    )):
        data.append({
            "id": i,
            "vector": embedding,
            "title": title,
            "text": content
        })

    # æ‰¹é‡æ’å…¥
    insert_result = milvus_client.insert(collection_name=collection_name, data=data)
    print(f"âœ… æˆåŠŸæ’å…¥ {insert_result['insert_count']} æ¡è®°å½•")

    return milvus_client, embedding_model, collection_name


def search_with_optimized_rag(
    question: str,
    milvus_client: MilvusClient,
    embedding_model,
    collection_name: str,
    top_k: int = 5
):
    """
    ä½¿ç”¨ä¼˜åŒ–çš„RAGç³»ç»Ÿè¿›è¡Œæœç´¢
    """

    print(f"\nğŸ” æœç´¢é—®é¢˜: {question}")

    # ç”ŸæˆæŸ¥è¯¢embedding
    query_embedding = embedding_model.encode_queries([question])

    # æ‰§è¡Œå‘é‡æœç´¢
    search_results = milvus_client.search(
        collection_name=collection_name,
        data=query_embedding,
        limit=top_k,
        search_params={"metric_type": "COSINE", "params": {}},
        output_fields=["title", "text"]
    )

    print(f"ğŸ“‹ æ£€ç´¢åˆ° {len(search_results[0])} ä¸ªç›¸å…³ç»“æœ:")

    retrieved_contexts = []
    for i, result in enumerate(search_results[0]):
        score = result["distance"]
        title = result["entity"]["title"]
        content = result["entity"]["text"]

        print(f"\n{i + 1}. ç›¸ä¼¼åº¦å¾—åˆ†: {score:.4f}")
        print(f"   æ ‡é¢˜: {title}")
        print(f"   å†…å®¹é¢„è§ˆ: {content[:150]}...")

        retrieved_contexts.append((title, content, score))

    return retrieved_contexts


def generate_answer_with_deepseek(question: str, contexts: List[Tuple[str, str, float]]):
    """
    ä½¿ç”¨DeepSeekç”Ÿæˆç­”æ¡ˆ
    """

    # æ„å»ºä¸Šä¸‹æ–‡
    context_text = "\n\n".join([content for _, content, _ in contexts])

    # æ„å»ºprompt
    SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ³•å¾‹AIåŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„æ³•å¾‹æ¡æ–‡ä¸Šä¸‹æ–‡ï¼Œå‡†ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
æ³¨æ„ï¼š
1. åªåŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. å¼•ç”¨å…·ä½“çš„æ³•æ¡æ—¶è¯·æ ‡æ˜æ¡æ–‡ç¼–å·
4. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€æ˜“æ‡‚
"""

    USER_PROMPT = f"""
è¯·åŸºäºä»¥ä¸‹æ³•å¾‹æ¡æ–‡å›ç­”é—®é¢˜ï¼š

<ä¸Šä¸‹æ–‡>
{context_text}
</ä¸Šä¸‹æ–‡>

<é—®é¢˜>
{question}
</é—®é¢˜>

è¯·æä¾›å‡†ç¡®çš„æ³•å¾‹è§£ç­”ï¼š
"""

    # è°ƒç”¨DeepSeek API
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        return "âŒ é”™è¯¯ï¼šæœªè®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡"

    client = OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com/v1"
    )

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": USER_PROMPT}
            ],
            temperature=0.1  # è¾ƒä½çš„temperatureç¡®ä¿å›ç­”çš„ä¸€è‡´æ€§
        )

        return response.choices[0].message.content

    except Exception as e:
        return f"âŒ è°ƒç”¨DeepSeek APIæ—¶å‡ºé”™: {str(e)}"


def main():
    """
    ä¸»æ¼”ç¤ºå‡½æ•°
    """

    print("=" * 60)
    print("ğŸš€ ä¼˜åŒ–RAGç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)

    # æ„å»ºRAGç³»ç»Ÿ
    import os
    script_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(script_dir, "mfd.md")
    milvus_client, embedding_model, collection_name = build_optimized_rag_system(file_path)

    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "æƒåˆ©äººã€åˆ©å®³å…³ç³»äººè®¤ä¸ºä¸åŠ¨äº§ç™»è®°ç°¿è®°è½½çš„äº‹é¡¹é”™è¯¯æ—¶æ€ä¹ˆåŠï¼Ÿ",
        "ä»€ä¹ˆæ˜¯å¼‚è®®ç™»è®°ï¼Ÿ",
        "ä¸åŠ¨äº§ç™»è®°ç°¿å’Œä¸åŠ¨äº§æƒå±è¯ä¹¦è®°è½½ä¸ä¸€è‡´æ—¶ä»¥å“ªä¸ªä¸ºå‡†ï¼Ÿ"
    ]

    for question in test_questions:
        print("\n" + "=" * 60)

        # æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
        contexts = search_with_optimized_rag(
            question,
            milvus_client,
            embedding_model,
            collection_name,
            top_k=3
        )

        # ç”Ÿæˆç­”æ¡ˆ
        print("\nğŸ¤– ç”Ÿæˆç­”æ¡ˆ:")
        answer = generate_answer_with_deepseek(question, contexts)
        print(answer)

        print("\n" + "-" * 60)

    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    main()
