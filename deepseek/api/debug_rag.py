#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGè°ƒè¯•å·¥å…·ï¼šè¯Šæ–­æ£€ç´¢é—®é¢˜
"""

import os
import re
from typing import List, Tuple
from pymilvus import MilvusClient, model as milvus_model
from sentence_transformers import SentenceTransformer


def load_and_parse_articles(file_path: str) -> List[Tuple[str, str]]:
    """åŠ è½½å¹¶è§£ææ¡æ–‡"""

    with open(file_path, "r", encoding="utf-8") as file:
        content = file.read()

    # ç®€å•æŒ‰æ¡æ–‡åˆ†å‰²è¿›è¡Œæµ‹è¯•
    article_pattern = r"\*\*ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡\*\*"

    # æ‰¾åˆ°æ‰€æœ‰æ¡æ–‡
    article_matches = list(re.finditer(article_pattern, content))

    articles = []
    for i, match in enumerate(article_matches):
        article_title = match.group(0)
        start_pos = match.start()

        # ç¡®å®šæ¡æ–‡å†…å®¹çš„ç»“æŸä½ç½®
        if i + 1 < len(article_matches):
            end_pos = article_matches[i + 1].start()
            article_content = content[start_pos:end_pos].strip()
        else:
            article_content = content[start_pos:].strip()

        articles.append((article_title, article_content))

    return articles


def debug_search():
    """è°ƒè¯•æœç´¢åŠŸèƒ½"""

    print("ğŸ” RAGç³»ç»Ÿè°ƒè¯•")
    print("=" * 50)

    # åŠ è½½æ•°æ®
    script_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(script_dir, "mfd.md")
    articles = load_and_parse_articles(file_path)

    print(f"ğŸ“Š æ€»å…±è§£æå‡º {len(articles)} ä¸ªæ¡æ–‡")

    # æ‰‹åŠ¨æŸ¥æ‰¾ç›®æ ‡æ¡æ–‡
    target_keywords = ["ä¸åŠ¨äº§ç™»è®°ç°¿", "é”™è¯¯", "æ›´æ­£", "å¼‚è®®"]

    print("\nğŸ¯ æ‰‹åŠ¨æœç´¢ç›¸å…³æ¡æ–‡:")
    relevant_articles = []

    for i, (title, content) in enumerate(articles):
        score = sum(1 for keyword in target_keywords if keyword in content)
        if score > 0:
            relevant_articles.append((score, i, title, content))

    # æŒ‰ç›¸å…³åº¦æ’åº
    relevant_articles.sort(key=lambda x: x[0], reverse=True)

    print(f"æ‰¾åˆ° {len(relevant_articles)} ä¸ªç›¸å…³æ¡æ–‡:")
    for j, (score, idx, title, content) in enumerate(relevant_articles[:5]):
        print(f"\n{j + 1}. ç›¸å…³åº¦: {score}, ç´¢å¼•: {idx}")
        print(f"   æ ‡é¢˜: {title}")
        print(f"   å†…å®¹: {content[:200]}...")

    if not relevant_articles:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ¡æ–‡ï¼")
        return

    # ä½¿ç”¨embeddingæ¨¡å‹æµ‹è¯•
    print("\nğŸ§  æµ‹è¯•Embeddingæ¨¡å‹:")
    print("æ­£åœ¨åŠ è½½ BAII/bge-large-zh-v1.5 Embedding æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
    embedding_model = SentenceTransformer('BAAI/bge-large-zh-v1.5')
    print("æ¨¡å‹åŠ è½½å®Œæˆã€‚")

    # æµ‹è¯•ç›®æ ‡æ¡æ–‡çš„embedding
    target_article = relevant_articles[0]  # æœ€ç›¸å…³çš„æ¡æ–‡
    target_content = target_article[3]

    print(f"ç›®æ ‡æ¡æ–‡: {target_article[2]}")

    # ç”Ÿæˆembedding
    query = "æƒåˆ©äººã€åˆ©å®³å…³ç³»äººè®¤ä¸ºä¸åŠ¨äº§ç™»è®°ç°¿è®°è½½çš„äº‹é¡¹é”™è¯¯æ—¶æ€ä¹ˆåŠï¼Ÿ"

    query_embedding = embedding_model.encode([query])[0]
    target_embedding = embedding_model.encode([target_content])[0]

    # è®¡ç®—ç›¸ä¼¼åº¦
    import numpy as np

    # ä½™å¼¦ç›¸ä¼¼åº¦
    def cosine_similarity(a, b):
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

    similarity = cosine_similarity(query_embedding, target_embedding)
    print(f"é—®é¢˜ä¸ç›®æ ‡æ¡æ–‡çš„ä½™å¼¦ç›¸ä¼¼åº¦: {similarity:.4f}")

    # æµ‹è¯•å…¶ä»–å‡ ä¸ªæ¡æ–‡çš„ç›¸ä¼¼åº¦
    print("\nğŸ“Š ä¸å…¶ä»–æ¡æ–‡çš„ç›¸ä¼¼åº¦å¯¹æ¯”:")

    test_indices = [0, 10, 50, 100, 200]  # æµ‹è¯•ä¸åŒä½ç½®çš„æ¡æ–‡

    for idx in test_indices:
        if idx < len(articles):
            test_content = articles[idx][1]
            test_embedding = embedding_model.encode([test_content])[0]
            test_similarity = cosine_similarity(query_embedding, test_embedding)

            print(f"æ¡æ–‡ {idx} ({articles[idx][0]}): {test_similarity:.4f}")

    # å°è¯•Milvusæœç´¢
    print("\nğŸ—„ï¸  æµ‹è¯•Milvusæœç´¢:")

    milvus_client = MilvusClient(uri="./debug_milvus.db")
    collection_name = "debug_collection"

    # åˆ é™¤å·²å­˜åœ¨çš„collection
    if milvus_client.has_collection(collection_name):
        milvus_client.drop_collection(collection_name)

    # åˆ›å»ºcollection
    milvus_client.create_collection(
        collection_name=collection_name,
        dimension=1024,
        metric_type="COSINE",
        consistency_level="Strong"
    )

    # æ’å…¥å°‘é‡æ•°æ®è¿›è¡Œæµ‹è¯•
    test_articles = articles[:20]  # ä½¿ç”¨å‰20ä¸ªæ¡æ–‡è¿›è¡Œæµ‹è¯•
    if relevant_articles:
        # æ·»åŠ æœ€ç›¸å…³çš„æ¡æ–‡ï¼ˆç¡®ä¿æ ¼å¼ä¸€è‡´ï¼‰
        target_score, target_idx, target_title, target_content = relevant_articles[0]
        test_articles.append((target_title, target_content))

    embeddings = embedding_model.encode([content for _, content in test_articles])

    data = []
    for i, ((title, content), embedding) in enumerate(zip(test_articles, embeddings)):
        data.append({
            "id": i,
            "vector": embedding,
            "title": title,
            "text": content
        })

    milvus_client.insert(collection_name=collection_name, data=data)

    # æ‰§è¡Œæœç´¢
    search_results = milvus_client.search(
        collection_name=collection_name,
        data=[query_embedding],
        limit=5,
        search_params={"metric_type": "COSINE", "params": {}},
        output_fields=["title", "text"]
    )

    print("ğŸ” Milvusæœç´¢ç»“æœ:")
    for i, result in enumerate(search_results[0]):
        score = result["distance"]
        title = result["entity"]["title"]

        print(f"{i + 1}. ç›¸ä¼¼åº¦: {score:.4f}")
        print(f"   æ ‡é¢˜: {title}")
        print(f"   å†…å®¹: {result['entity']['text'][:100]}...")


if __name__ == "__main__":
    debug_search()
